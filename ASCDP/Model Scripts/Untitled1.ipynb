{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e60c889-f306-4368-961d-5d017d3628e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jun 11 07:13:23 2025\n",
    "\n",
    "@author: lizamclatchy\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#Using a regression model to adequately predict wind data, not forecasting, learning and predicting missing\n",
    "combined_df = pd.read_csv(\"/Users/lizamclatchy/ASCDP/Data Cleaning/Cleaned Model Input Data/train_afono_windspeed.csv\")\n",
    "selected_columns = ['TIMESTAMP', 'WS_mph_S_WVT'] + [col for col in combined_df.columns if col not in ['TIMESTAMP', 'WS_mph_S_WVT']]\n",
    "rh_data = combined_df[selected_columns].copy()\n",
    "rh_data = rh_data.dropna(subset=['WS_mph_S_WVT'])  # Keep only rows where RH_Aasu is not NaN\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'])\n",
    "    target_column = 'WS_mph_S_WVT'\n",
    "    feature_cols = [col for col in df.columns if col not in ['TIMESTAMP', target_column,'Elevation_target','synoptic_elevation_1','synoptic_elevation_0']]    \n",
    "    for col in feature_cols:\n",
    "        df[f'{col}_lag1'] = df[col].shift(2)\n",
    "        df[f'{col}_lag3'] = df[col].shift(5)\n",
    "        df[f'{col}_lag6'] = df[col].shift(7)\n",
    "        df[f'{col}_rolling2'] = df[col].rolling(window=2).mean()\n",
    "        df[f'{col}_rolling4'] = df[col].rolling(window=4).mean()\n",
    "        df[f'{col}_rolling6'] = df[col].rolling(window=6).mean()\n",
    "    \n",
    "    # Add more granular time features\n",
    "    df['hour_of_day'] = pd.to_datetime(df['TIMESTAMP']).dt.hour\n",
    "    df['is_daytime'] = ((df['hour_of_day'] >= 6) & (df['hour_of_day'] <= 18)).astype(int)\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour_of_day'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour_of_day'] / 24)\n",
    "\n",
    "    # Day of Week (0=Monday, 6=Sunday)\n",
    "    df['day_of_week'] = df['TIMESTAMP'].dt.dayofweek\n",
    "    # Season (simplified meteorological)\n",
    "    df['month'] = df['TIMESTAMP'].dt.month\n",
    "    def get_season(month):\n",
    "        if month in [12, 1, 2]:\n",
    "            return \"winter\"\n",
    "        elif month in [3, 4, 5]:\n",
    "            return \"spring\"\n",
    "        elif month in [6, 7, 8]:\n",
    "            return \"summer\"\n",
    "        else:\n",
    "            return \"fall\"\n",
    "    \n",
    "    df['season'] = df['month'].apply(get_season)\n",
    "    # Enforce season as categorical with all 4 categories\n",
    "    df['season'] = pd.Categorical(df['season'], categories=[\"winter\", \"spring\", \"summer\", \"fall\"])\n",
    "    # One-hot encode with fixed categories\n",
    "    season_dummies = pd.get_dummies(df['season'], prefix='season')\n",
    "    season_dummies = season_dummies.astype(int)\n",
    "    df = pd.concat([df, season_dummies], axis=1)\n",
    "    df.drop(columns=['season'], inplace=True)\n",
    "\n",
    "    # Heat Index (approximation using air temp and RH)\n",
    "    if 'AirTF_target' in df.columns and 'RH_target' in df.columns:\n",
    "        df['heat_index_target'] = df['AirTF_target'] * df['RH_target'] / 100\n",
    "        df['temp_trend_1h_target'] = df['AirTF_target'].rolling(6).apply(lambda x: x.iloc[-1] - x.iloc[0], raw=False)\n",
    "    for col in df.columns:\n",
    "        if col != 'TIMESTAMP':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Now add interaction terms here (currently commented out)\n",
    "    df['wind_per_rh'] = df['wind_speed_weighted_0_rolling6'] / (df['relative_humidity_weighted_0_rolling6'] + 1e-3)\n",
    "    df['solar_per_temp'] = df['SolarMJ_target_rolling4'] / (df['air_temp_weighted_0_rolling6'] + 1e-3)\n",
    "    \n",
    "    interaction_pairs = [\n",
    "    ('RH_target', 'air_temp_weighted_1_rolling2'),\n",
    "    ('RH_target_rolling2', 'air_temp_weighted_0_rolling4'),\n",
    "    ('relative_humidity_weighted_1_rolling2', 'air_temp_weighted_0_rolling2'),\n",
    "    ('SolarMJ_target_lag1', 'RH_target_rolling2'),\n",
    "    ('SolarMJ_target_rolling4', 'air_temp_weighted_1_rolling2'),\n",
    "    ('SolarMJ_target_rolling4', 'relative_humidity_weighted_1_rolling2'),\n",
    "    ('wind_speed_weighted_1_rolling6', 'RH_target'),\n",
    "    ('wind_speed_weighted_1_rolling6', 'SolarMJ_target_rolling4'),\n",
    "    ('season_summer', 'RH_target_rolling2'),\n",
    "    ('season_summer', 'SolarMJ_target_lag1'),\n",
    "    ('season_summer', 'PTemp_target'),\n",
    "]\n",
    "    \n",
    "    for col1, col2 in interaction_pairs:\n",
    "        if col1 in df.columns and col2 in df.columns:\n",
    "            df[f'{col1}__X__{col2}'] = df[col1] * df[col2]\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def cross_validate_model(model, X, y, n_splits=5):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    train_scores, val_scores = [], []\n",
    "\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        train_pred = model.predict(X_tr)\n",
    "        val_pred = model.predict(X_val)\n",
    "\n",
    "        train_mae = mean_absolute_error(y_tr, train_pred)\n",
    "        val_mae = mean_absolute_error(y_val, val_pred)\n",
    "\n",
    "        train_scores.append(train_mae)\n",
    "        val_scores.append(val_mae)\n",
    "\n",
    "        print(f\"Fold {len(train_scores)} - Train MAE: {train_mae:.4f}, Val MAE: {val_mae:.4f}\")\n",
    "\n",
    "    return train_scores, val_scores\n",
    "\n",
    "\n",
    "def xgboost_regression(train_df, target_column, n_splits=5):\n",
    "    # --- 1. Prepare Data ---\n",
    "    train_df = train_df.sort_values(by=\"TIMESTAMP\")\n",
    "    train_data, test_data = train_test_split(train_df, test_size=0.2, shuffle=False)\n",
    "    train_data = feature_engineering(train_data).dropna()\n",
    "    test_data = feature_engineering(test_data).dropna()\n",
    "\n",
    "    X_train = train_data.drop(columns=[target_column, 'TIMESTAMP'])\n",
    "    y_train = train_data[target_column]\n",
    "    X_test = test_data.drop(columns=[target_column, 'TIMESTAMP'])\n",
    "    y_test = test_data[target_column]\n",
    "\n",
    "    # --- 2. Visualize Train-Test Split ---\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    ax.plot(train_data.index, y_train, label='Training Set')\n",
    "    ax.plot(test_data.index, y_test, label='Test Set', linestyle=\"dashed\")\n",
    "    ax.set_title(f'Data Train/Test Split for {target_column}')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # --- 3. Define Objective Function for Optuna with CV ---\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 1),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),\n",
    "            'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True),\n",
    "            'objective': 'reg:squarederror',\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        model = XGBRegressor(**params)\n",
    "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "        mae_scores = []\n",
    "    \n",
    "        for train_index, val_index in tscv.split(X_train):\n",
    "            X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "            model.fit(X_tr, y_tr)\n",
    "            preds = model.predict(X_val)\n",
    "            mae_scores.append(mean_absolute_error(y_val, preds))\n",
    "    \n",
    "        return np.mean(mae_scores)\n",
    "\n",
    "    # --- 4. Run Optuna ---\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    best_params = study.best_params\n",
    "    print(\"Best Params:\", best_params)\n",
    "\n",
    "    # --- 5. Cross-Validate Best Model and Default Model ---\n",
    "    best_model = XGBRegressor(**best_params)\n",
    "    default_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "    train_mae_best, val_mae_best = cross_validate_model(best_model, X_train, y_train, n_splits=n_splits)\n",
    "    train_mae_default, val_mae_default = cross_validate_model(default_model, X_train, y_train, n_splits=n_splits)\n",
    "\n",
    "    # --- 6. Plot CV Results ---\n",
    "    folds = range(1, len(train_mae_best) + 1)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(folds, train_mae_default, 'o-', label='Default Train MAE')\n",
    "    plt.plot(folds, val_mae_default, 'o--', label='Default Val MAE')\n",
    "    plt.plot(folds, train_mae_best, 's-', label='Tuned Train MAE')\n",
    "    plt.plot(folds, val_mae_best, 's--', label='Tuned Val MAE')\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.title(\"Train vs Validation MAE per Fold (Default vs Tuned)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- 7. Fit Final Model and Evaluate ---\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lr = LinearRegression().fit(X_train, y_train)\n",
    "    print(\"MAE (Linear):\", mean_absolute_error(y_test, lr.predict(X_test)))\n",
    "\n",
    "    smape_error = smape(y_test, y_pred)\n",
    "    print(f\"SMAPE: {smape_error:.2f}%\")\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"MAE: {mae:.4f} mph\")\n",
    "    print(f\"RÂ²:    {r2:.4f}\")\n",
    "\n",
    "    # --- 8. Plot Final Prediction ---\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_test.index, y_test, label='Actual', color='blue')\n",
    "    plt.plot(y_test.index, y_pred, label='Predicted', linestyle='--', color='red')\n",
    "    plt.title(f'Actual vs Predicted Wind Speed ({target_column})')\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(\"Wind Speed (log-transformed)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    from xgboost import plot_importance\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plot_importance(best_model, importance_type='gain', max_num_features=15, title='XGBoost Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return best_model, y_test, y_pred\n",
    "\n",
    "model, y_test, y_pred = xgboost_regression(rh_data, 'WS_mph_S_WVT')\n",
    "#fe_df = feature_engineering(rh_data)\n",
    "#fe_df.set_index(\"TIMESTAMP\").to_csv(\"feature_engineered_data_with_index.csv\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test.index, y_test, label='Actual WS_mph_S_WVT_Afono', color='blue')\n",
    "plt.plot(y_test.index, y_pred, label='Predicted RWS_mph_S_WVT_Afono', color='red', linestyle='--')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Speed (MPH)')\n",
    "plt.title('Actual vs Predicted WS_mph_S_WVT_Afono')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(residuals, label='Residuals')\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.title(\"Prediction Residuals Over Time\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
